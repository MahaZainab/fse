{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b590d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf16a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (3.10.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pc\\appdata\\roaming\\python\\python312\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5569306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eea287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "STUDENT_MODEL = \"llama3.1:8b\"\n",
    "TEACHER_MODEL = \"llama3.1:70b\"\n",
    "SCORE_MAX = 3\n",
    "\n",
    "\n",
    "def call_llm_LangChain_correct_v2(prompt, temperature=0.0):\n",
    "    llm = ChatOllama(\n",
    "        model=\"llama3.1:8b\",\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "\n",
    "You are a large language model acting as a judge for assessing the performance of a Teaching Assistant (TA) in an introductory Python programming course.\n",
    "\n",
    "The TA is an LLM that answers student questions about Python code. Your job is to evaluate the quality of the TA's answer.\n",
    "\n",
    "You will receive:\n",
    "- A Python code snippet\n",
    "- A student question about that code\n",
    "- A reference (correct) answer\n",
    "- A TA LLM-generated answer (called the prediction)\n",
    "\n",
    "Your task is to evaluate how well the TA's prediction answers the student's question, using the following four dimensions. For each, provide:\n",
    "- An integer score from 1 to 3\n",
    "\n",
    "\n",
    "\n",
    "### Accuracy\n",
    "Compare the prediction with the reference to assess factual correctness and understanding of the code’s behavior and intent.\n",
    "You must judge whether the prediction reflects accurate behavior and matches core facts from the reference. \n",
    "You need to consider semantic meaning of code comprehension: understanding the structure, functionality, and intent behind the code.\\n\"\n",
    "\n",
    "Score meanings:\n",
    "- 1: Completely incorrect or irrelevant; does not address the reference answer.\n",
    "- 2: Partially correct; some key facts are accurate, but major details are wrong or missing.\n",
    "- 3: Fully correct; matches the reference answer in meaning and factual content.\n",
    "\n",
    "### Completeness\n",
    "Check if the prediction covers all important parts of the reference answer, including key concepts or conditions.\n",
    "\n",
    "Score meanings:\n",
    "- 1: Omits most key information or contains only a tiny fragment of relevant content.\n",
    "- 2: Covers some elements but misses important parts.\n",
    "- 3: Fully covers all essential information from the reference.\n",
    "\n",
    "### Relevance\n",
    "Assess whether the prediction directly addresses the question and stays on-topic.\n",
    "\n",
    "Score meanings:\n",
    "- 1: Completely irrelevant or mostly unrelated.\n",
    "- 2: Partially related but misses the main point.\n",
    "- 3: Fully focused and directly answers the question.\n",
    "\n",
    "### Clarity\n",
    "Evaluate how clearly and logically the prediction is expressed, ensuring it is easy to understand.\n",
    "\n",
    "Score meanings:\n",
    "- 1: Confusing, vague, or incoherent.\n",
    "- 2: Understandable but awkwardly phrased or slightly unclear.\n",
    "- 3: Clear, concise, and easy to follow.\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "Code:\n",
    "```python\n",
    "def count_even(nums):\n",
    "    total = 0\n",
    "    for x in nums:\n",
    "        if x % 2 == 0:\n",
    "            total += 1\n",
    "    return total\n",
    "Question: What does this function return when given a list of integers?\n",
    "Reference Answer: It returns the count of even numbers in the list.\n",
    "Prediction: It returns the count of odd numbers in the list.\n",
    "\n",
    "Evaluation Output:\n",
    "{\n",
    "\n",
    "\"accuracy\": { \"score\": 1 },\n",
    "\"completeness\": { \"score\": 1 },\n",
    "\"relevance\": { \"score\": 2 },\n",
    "\"clarity\": { \"score\": 3 }\n",
    "\n",
    "}\n",
    "\n",
    "Final Instructions:\n",
    "For the given input (code, question, reference answer, and prediction), evaluate the prediction on the four metrics defined above.\n",
    "Base your evaluation strictly on the content provided. Do not hallucinate missing information. Be consistent and objective.\n",
    "Do not include reasoning or explanations.\n",
    "\n",
    "Respond only with a JSON object in the exact format:\n",
    "{\n",
    "\"accuracy\": { \"score\": 1-3},\n",
    "\"completeness\": {\"score\": 1-3},\n",
    "\"relevance\": {\"score\": 1-3},\n",
    "\"clarity\": {\"score\": 1-3}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dab7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_teacher_single_turn(code, question, reference, prediction, scores):\n",
    "    # Build teacher system prompt\n",
    "    system_prompt = \"\"\"\n",
    "You are a 70B teacher LLM model reviewing a student LLM-as-judge's evaluation of a Teaching Assistant's (TA) answer.\n",
    "\n",
    "You will receive:\n",
    "- Python code snippet\n",
    "- Student's question\n",
    "- Reference (correct) answer\n",
    "- TA's predicted answer\n",
    "- Scores assigned by the student LLM-as-judge\n",
    "\n",
    "Your task:\n",
    "- Examine the TA's predicted answer in context of the code, question, and reference.\n",
    "- For any dimension (Accuracy, Completeness, Relevance, Clarity) where the score is less than 3,\n",
    "  provide clear, concise feedback (2–4 sentences) explaining what could be improved.\n",
    "- If a dimension has no issues, do not include it in your response.\n",
    "\n",
    "Respond ONLY with a JSON object where keys are the dimension names (lowercase)\n",
    "and values are the feedback strings.\n",
    "\n",
    "Example output:\n",
    "{\n",
    "  \"accuracy\": \"The prediction misrepresents the function’s return value.\",\n",
    "  \"clarity\": \"The explanation lacks structure and is hard to follow.\"\n",
    "}\n",
    "\n",
    "Rubric:\n",
    "\n",
    "### Accuracy\n",
    "- 1: Completely incorrect or irrelevant.\n",
    "- 2: Partially correct but with major mistakes or omissions.\n",
    "- 3: Fully correct and matches the reference.\n",
    "\n",
    "### Completeness\n",
    "- 1: Omits most key information.\n",
    "- 2: Covers some but misses important parts.\n",
    "- 3: Fully covers all essential information.\n",
    "\n",
    "### Relevance\n",
    "- 1: Irrelevant or mostly unrelated.\n",
    "- 2: Partially related but misses main point.\n",
    "- 3: Fully focused and directly addresses the question.\n",
    "\n",
    "### Clarity\n",
    "- 1: Confusing, vague, or incoherent.\n",
    "- 2: Understandable but awkwardly phrased or unclear.\n",
    "- 3: Clear, concise, and easy to understand.\n",
    "\"\"\"\n",
    "\n",
    "    # Format input for the teacher\n",
    "    user_prompt = f\"\"\"\n",
    "```python\n",
    "{code}\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Reference Answer:\n",
    "{reference}\n",
    "\n",
    "TA's Predicted Answer:\n",
    "{prediction}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        llm = ChatOllama(model=TEACHER_MODEL, temperature=0.0)\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt.strip()),\n",
    "            HumanMessage(content=user_prompt.strip())\n",
    "        ]\n",
    "        response = llm.invoke(messages)\n",
    "        critiques = json.loads(response.content.strip())\n",
    "        return critiques\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ade6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_reflect_and_revise(code, question, reference, prediction, old_score, critiques):\n",
    "    print(\"\\n Student reflecting on teacher feedback...\\n\")\n",
    "\n",
    "    critique_text = \"\\n\".join(\n",
    "        f\"{dim.upper()} Feedback: {critique.strip()}\" for dim, critique in critiques.items()\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Code:\n",
    "```python\n",
    "{code}\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Reference Answer:\n",
    "{reference}\n",
    "\n",
    "TA's Predicted Answer:\n",
    "{prediction}\n",
    "\n",
    "Teacher's Feedback:\n",
    "{critique_text}\n",
    "\n",
    "Old prediction:\n",
    "{old_score}\n",
    "\n",
    "You have to update the old prediction by considering Teacher's Feedback. Please re-evaluate the TA's answer using:\n",
    "\n",
    "Accuracy\n",
    "\n",
    "Completeness\n",
    "\n",
    "Relevance\n",
    "\n",
    "Clarity\n",
    "\n",
    "Only return JSON:\n",
    "{{\n",
    "\"accuracy\": {{ \"score\": 1-3 }},\n",
    "\"completeness\": {{ \"score\": 1-3 }},\n",
    "\"relevance\": {{ \"score\": 1-3 }},\n",
    "\"clarity\": {{ \"score\": 1-3 }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = call_llm_LangChain_correct_v2(prompt, temperature=0.0)\n",
    "        revised_scores = json.loads(response)\n",
    "        print(\" Revised Scores:\\n\", revised_scores)\n",
    "    except Exception as e:\n",
    "        print(\" Failed to parse revised scores:\", str(e))\n",
    "        revised_scores = None\n",
    "\n",
    "    return revised_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53857fa7",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a803d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples (N): 56085\n",
      "Example keys: ['id', 'code', 'question', 'reference', 'prediction', 'accuracy', 'completeness', 'relevance', 'clarity']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# TODO: set your full dataset path (the complete JSON list)\n",
    "FULL_DATA_JSON = \"Mistral_CodeQA_llm_judge.json\"\n",
    "\n",
    "with open(FULL_DATA_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    examples = json.load(f)\n",
    "\n",
    "N_total = len(examples)\n",
    "print(\"Total examples (N):\", N_total)\n",
    "print(\"Example keys:\", list(examples[0].keys()) if examples else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fb60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "def _extract_json_object(text: str):\n",
    "    # Try direct parse\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Try to find first JSON object\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        try:\n",
    "            return json.loads(m.group(0))\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def flatten_scores(score_obj):\n",
    "    \"\"\"Converts either nested JSON {'accuracy':{'score':2}} or flat {'accuracy':2} into flat ints.\"\"\"\n",
    "    out = {}\n",
    "    for k in [\"accuracy\",\"completeness\",\"relevance\",\"clarity\"]:\n",
    "        v = score_obj.get(k, None) if isinstance(score_obj, dict) else None\n",
    "        if isinstance(v, dict) and \"score\" in v:\n",
    "            out[k] = v.get(\"score\")\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "def judge_scores_flat(code, question, reference, prediction):\n",
    "    prompt = f\"\"\"\n",
    "Code:\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Reference Answer:\n",
    "{reference}\n",
    "\n",
    "TA's Predicted Answer:\n",
    "{prediction}\n",
    "\"\"\"\n",
    "\n",
    "    raw = call_llm_LangChain_correct_v2(prompt, temperature=0.0)\n",
    "    obj = _extract_json_object(raw)\n",
    "    if obj is None:\n",
    "        raise ValueError(f\"Judge returned non-JSON. Raw:\\n{raw}\")\n",
    "    return flatten_scores(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5d913a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judging:   0%|          | 0/56085 [00:00<?, ?it/s]C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_15644\\3587777940.py:10: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(\n",
      "Judging:   0%|          | 4/56085 [03:32<826:17:57, 53.04s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m judge_scores_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m tqdm(examples, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJudging\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mjudge_scores_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreference\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     judge_scores_list\u001b[38;5;241m.\u001b[39mappend(s)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJudged:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(judge_scores_list))\n",
      "Cell \u001b[1;32mIn[8], line 45\u001b[0m, in \u001b[0;36mjudge_scores_flat\u001b[1;34m(code, question, reference, prediction)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjudge_scores_flat\u001b[39m(code, question, reference, prediction):\n\u001b[0;32m     30\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124mCode:\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m```python\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     raw \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm_LangChain_correct_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     obj \u001b[38;5;241m=\u001b[39m _extract_json_object(raw)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[4], line 112\u001b[0m, in \u001b[0;36mcall_llm_LangChain_correct_v2\u001b[1;34m(prompt, temperature)\u001b[0m\n\u001b[0;32m     15\u001b[0m     system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124mYou are a large language model acting as a judge for assessing the performance of a Teaching Assistant (TA) in an introductory Python programming course.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    107\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    108\u001b[0m         SystemMessage(content\u001b[38;5;241m=\u001b[39msystem_prompt),\n\u001b[0;32m    109\u001b[0m         HumanMessage(content\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m    110\u001b[0m     ]\n\u001b[1;32m--> 112\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\chat_models\\ollama.py:291\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    269\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    299\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[0;32m    300\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\chat_models\\ollama.py:222\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    215\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    221\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    224\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _chat_stream_response_to_chat_generation_chunk(stream_resp)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\chat_models\\ollama.py:194\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    186\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m    187\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    190\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_messages_to_ollama_messages(messages),\n\u001b[0;32m    193\u001b[0m     }\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload, stop\u001b[38;5;241m=\u001b[39mstop, api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    196\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    573\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\response.py:1063\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\response.py:1219\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\response.py:1138\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "judge_scores_list = []\n",
    "for ex in tqdm(examples, desc=\"Judging\"):\n",
    "    s = judge_scores_flat(ex.get(\"code\",\"\"), ex.get(\"question\",\"\"), ex.get(\"reference\",\"\"), ex.get(\"prediction\",\"\"))\n",
    "    judge_scores_list.append(s)\n",
    "\n",
    "print(\"Judged:\", len(judge_scores_list))\n",
    "print(\"First judged scores:\", judge_scores_list[0] if judge_scores_list else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207c5a0",
   "metadata": {},
   "source": [
    "## Budget policies: Random-K and Worst-first-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4652a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "budgets = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "def K_from_budget(b, N):\n",
    "    return int(math.floor(b * N))\n",
    "\n",
    "def pick_indices_random(N, b, seed=42):\n",
    "    K = K_from_budget(b, N)\n",
    "    rnd = random.Random(seed + int(b*1000))\n",
    "    if K == 0:\n",
    "        return set()\n",
    "    return set(rnd.sample(range(N), K))\n",
    "\n",
    "def need_score_from_judge(scores_flat):\n",
    "    # Higher means more need (worse initial evaluation)\n",
    "    a = scores_flat.get(\"accuracy\", 3) or 3\n",
    "    c = scores_flat.get(\"completeness\", 3) or 3\n",
    "    r = scores_flat.get(\"relevance\", 3) or 3\n",
    "    l = scores_flat.get(\"clarity\", 3) or 3\n",
    "    # simple weighted \"badness\"\n",
    "    return 0.5*(3 - a) + 0.2*(3 - c) + 0.15*(3 - r) + 0.15*(3 - l)\n",
    "\n",
    "def pick_indices_worst_first(judge_scores_list, b):\n",
    "    N = len(judge_scores_list)\n",
    "    K = K_from_budget(b, N)\n",
    "    if K == 0:\n",
    "        return set()\n",
    "    ranked = sorted(range(N), key=lambda i: need_score_from_judge(judge_scores_list[i]), reverse=True)\n",
    "    return set(ranked[:K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab4c33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "random b=0.0:   0%|          | 4/56085 [00:00<00:07, 7489.83it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_by_budget\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Run RANDOM policy\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m results_random_by_budget \u001b[38;5;241m=\u001b[39m \u001b[43mrun_budget_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselector_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpick_indices_random\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Run WORST-FIRST policy\u001b[39;00m\n\u001b[0;32m     45\u001b[0m results_worst_by_budget \u001b[38;5;241m=\u001b[39m run_budget_policy(\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworst_first\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     selector_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m b: pick_indices_worst_first(judge_scores_list, b)\n\u001b[0;32m     48\u001b[0m )\n",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m, in \u001b[0;36mrun_budget_policy\u001b[1;34m(policy_name, selector_fn)\u001b[0m\n\u001b[0;32m      8\u001b[0m budget_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(examples, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolicy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m b=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m---> 11\u001b[0m     old_scores \u001b[38;5;241m=\u001b[39m \u001b[43mjudge_scores_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# flat ints\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     teacher_feedbacks \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     13\u001b[0m     revised_scores \u001b[38;5;241m=\u001b[39m old_scores\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_budget_policy(policy_name: str, selector_fn):\n",
    "    results_by_budget = {}\n",
    "    for b in budgets:\n",
    "        intervene_set = selector_fn(b)\n",
    "        budget_results = []\n",
    "\n",
    "        for i, ex in enumerate(tqdm(examples, desc=f\"{policy_name} b={b}\")):\n",
    "            old_scores = judge_scores_list[i]  # flat ints\n",
    "            teacher_feedbacks = {}\n",
    "            revised_scores = old_scores\n",
    "\n",
    "            if i in intervene_set:\n",
    "                teacher_feedbacks = call_teacher_single_turn(\n",
    "                    ex.get(\"code\",\"\"), ex.get(\"question\",\"\"), ex.get(\"reference\",\"\"), ex.get(\"prediction\",\"\"), old_scores\n",
    "                )\n",
    "                # student_reflect_and_revise expects critiques dict\n",
    "                revised_scores = student_reflect_and_revise(\n",
    "                    ex.get(\"code\",\"\"), ex.get(\"question\",\"\"), ex.get(\"reference\",\"\"), ex.get(\"prediction\",\"\"),\n",
    "                    old_scores, teacher_feedbacks\n",
    "                ) or old_scores  # fallback\n",
    "\n",
    "            budget_results.append({\n",
    "                \"id\": ex.get(\"id\", i),\n",
    "                \"budget\": b,\n",
    "                \"intervened\": (i in intervene_set),\n",
    "                \"old_scores\": old_scores,\n",
    "                \"teacher_feedbacks\": teacher_feedbacks,\n",
    "                \"new_scores\": revised_scores\n",
    "            })\n",
    "\n",
    "        results_by_budget[b] = budget_results\n",
    "        print(f\"[{policy_name}] Budget={b}: teacher calls={len(intervene_set)} / N={len(examples)}\")\n",
    "    return results_by_budget\n",
    "\n",
    "# Run RANDOM policy\n",
    "results_random_by_budget = run_budget_policy(\n",
    "    \"random\",\n",
    "    selector_fn=lambda b: pick_indices_random(len(examples), b, seed=42)\n",
    ")\n",
    "\n",
    "# Run WORST-FIRST policy\n",
    "results_worst_by_budget = run_budget_policy(\n",
    "    \"worst_first\",\n",
    "    selector_fn=lambda b: pick_indices_worst_first(judge_scores_list, b)\n",
    ")\n",
    "\n",
    "# Save\n",
    "with open(\"results_random_by_budget.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_random_by_budget, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(\"results_worst_by_budget.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_worst_by_budget, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved results_random_by_budget.json and results_worst_by_budget.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e565089",
   "metadata": {},
   "source": [
    "## Compute per-budget metric curves and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def metric_avg_accuracy_norm(results):\n",
    "    # results: list of dicts for a budget\n",
    "    vals = []\n",
    "    for r in results:\n",
    "        s = r[\"new_scores\"]\n",
    "        vals.append((s.get(\"accuracy\", 3) or 3) / 3.0)\n",
    "    return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "def make_curve(results_by_budget):\n",
    "    return [metric_avg_accuracy_norm(results_by_budget[b]) for b in budgets]\n",
    "\n",
    "curve_random = make_curve(results_random_by_budget)\n",
    "curve_worst = make_curve(results_worst_by_budget)\n",
    "\n",
    "print(\"Budgets:\", budgets)\n",
    "print(\"Random curve:\", curve_random)\n",
    "print(\"Worst-first curve:\", curve_worst)\n",
    "\n",
    "# Save curves\n",
    "with open(\"metric_curves.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"budgets\": budgets,\n",
    "        \"random_avg_accuracy_norm\": curve_random,\n",
    "        \"worst_first_avg_accuracy_norm\": curve_worst\n",
    "    }, f, indent=2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(budgets, curve_random, marker=\"o\", label=\"Random-K\")\n",
    "plt.plot(budgets, curve_worst, marker=\"o\", label=\"Worst-first-K\")\n",
    "plt.xlabel(\"Budget b (fraction of FULL dataset)\")\n",
    "plt.ylabel(\"Avg accuracy score (normalized 0..1)\")\n",
    "plt.title(\"Single-turn: Metric vs Budget\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
